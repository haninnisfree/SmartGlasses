"""
ë³´ê³ ì„œ ìƒì„± ëª¨ë“ˆ
AI ê¸°ë°˜ í•™ìˆ ì  ë³´ê³ ì„œ ìë™ ìƒì„±
CREATED 2024-12-20: í´ë” ê¸°ë°˜ ë¬¸ì„œ ë¶„ì„ ë° êµ¬ì¡°í™”ëœ ë³´ê³ ì„œ ìƒì„±
"""
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import uuid
import asyncio
from openai import AsyncOpenAI
from config.settings import settings
from utils.logger import get_logger

logger = get_logger(__name__)

class ReportGenerator:
    """í•™ìˆ ì  ë³´ê³ ì„œ ìë™ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = "gpt-4o-mini"
    
    async def generate_report(
        self,
        folder_id: str,
        selected_files: List[Dict],
        documents_content: List[str],
        custom_title: Optional[str] = None
    ) -> Dict:
        """
        ì„ íƒëœ ë¬¸ì„œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìˆ ì  ë³´ê³ ì„œ ìƒì„±
        
        Args:
            folder_id: í´ë” ID
            selected_files: ì„ íƒëœ íŒŒì¼ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            documents_content: ë¬¸ì„œ ë‚´ìš© ë¦¬ìŠ¤íŠ¸
            custom_title: ì‚¬ìš©ì ì§€ì • ì œëª© (ì„ íƒì‚¬í•­)
        
        Returns:
            êµ¬ì¡°í™”ëœ ë³´ê³ ì„œ ë°ì´í„°
        """
        try:
            logger.info(f"ë³´ê³ ì„œ ìƒì„± ì‹œì‘ - í´ë”: {folder_id}, íŒŒì¼ ìˆ˜: {len(selected_files)}")
            
            # 1. ë¬¸ì„œ ë‚´ìš© í†µí•© ë° ë¶„ì„
            combined_content = await self._combine_documents(documents_content)
            
            # 2. ì£¼ìš” í‚¤ì›Œë“œ ë° ì£¼ì œ ë¶„ì„
            analysis_result = await self._analyze_content(combined_content)
            
            # 3. ë³´ê³ ì„œ êµ¬ì¡° ìƒì„±
            if custom_title:
                title = custom_title
                subtitle = await self._generate_subtitle(title, analysis_result)
            else:
                title, subtitle = await self._generate_title_and_subtitle(analysis_result)
            
            # 4. ê° ì„¹ì…˜ ìƒì„± (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬)
            tasks = [
                self._generate_introduction(analysis_result, title),
                self._generate_main_content(combined_content, analysis_result),
                self._generate_conclusion(analysis_result, title)
            ]
            
            introduction, main_content, conclusion = await asyncio.gather(*tasks)
            
            # 5. ë³´ê³ ì„œ ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = await self._generate_metadata(
                selected_files, combined_content, introduction, main_content, conclusion
            )
            
            # 6. ìµœì¢… ë³´ê³ ì„œ êµ¬ì¡° ìƒì„±
            report_data = {
                "report_id": str(uuid.uuid4()),
                "folder_id": folder_id,
                "title": title,
                "subtitle": subtitle,
                "selected_files": selected_files,
                "report_structure": {
                    "introduction": introduction,
                    "main_content": main_content,
                    "conclusion": conclusion
                },
                "analysis_summary": analysis_result,
                "metadata": metadata,
                "visual_format": {
                    "layout_type": "academic",
                    "include_charts": False,
                    "include_images": False,
                    "color_scheme": "professional"
                },
                "created_at": datetime.utcnow(),
                "updated_at": datetime.utcnow()
            }
            
            logger.info(f"ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ - ID: {report_data['report_id']}")
            return report_data
            
        except Exception as e:
            logger.error(f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    async def _combine_documents(self, documents_content: List[str]) -> str:
        """ë¬¸ì„œ ë‚´ìš©ë“¤ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê²°í•©"""
        try:
            # ê° ë¬¸ì„œ ë‚´ìš©ì„ êµ¬ë¶„ìë¡œ ë¶„ë¦¬í•˜ì—¬ ê²°í•©
            combined = "\n\n=== ë¬¸ì„œ êµ¬ë¶„ ===\n\n".join(documents_content)
            
            # ë„ˆë¬´ ê¸´ ê²½ìš° ìš”ì•½ ì²˜ë¦¬
            if len(combined) > 15000:  # ì•½ 15K ë¬¸ì ì œí•œ
                combined = await self._summarize_long_content(combined)
            
            return combined
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ê²°í•© ì‹¤íŒ¨: {e}")
            raise
    
    async def _summarize_long_content(self, content: str) -> str:
        """ê¸´ ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ ì²˜ë¦¬ ê°€ëŠ¥í•œ í¬ê¸°ë¡œ ì¶•ì†Œ"""
        try:
            prompt = f"""
            ë‹¤ìŒ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì„ ì£¼ìš” í•µì‹¬ ë‚´ìš©ë§Œ í¬í•¨í•˜ì—¬ ìš”ì•½í•´ì£¼ì„¸ìš”.
            í•™ìˆ ì  ë³´ê³ ì„œ ì‘ì„±ì— í•„ìš”í•œ ì¤‘ìš”í•œ ì •ë³´ë“¤ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
            
            ë¬¸ì„œ ë‚´ìš©:
            {content[:10000]}  # ì²« 10K ë¬¸ìë§Œ ì‚¬ìš©
            
            ìš”ì•½ ìš”êµ¬ì‚¬í•­:
            - ì£¼ìš” ê°œë…ê³¼ í•µì‹¬ ë‚´ìš© ë³´ì¡´
            - ë°ì´í„°, í†µê³„, ì‚¬ì‹¤ ì •ë³´ ìš°ì„  ë³´ì¡´
            - í•™ìˆ ì  ë§¥ë½ê³¼ ë…¼ë¦¬ì  êµ¬ì¡° ìœ ì§€
            - 5000ì ì´ë‚´ë¡œ ìš”ì•½
            """
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=2000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"ê¸´ ë‚´ìš© ìš”ì•½ ì‹¤íŒ¨: {e}")
            return content[:10000]  # ì‹¤íŒ¨ ì‹œ ì²« 10K ë¬¸ìë§Œ ë°˜í™˜
    
    async def _analyze_content(self, content: str) -> Dict:
        """ë¬¸ì„œ ë‚´ìš© ë¶„ì„ ë° ì£¼ìš” ì£¼ì œ ì¶”ì¶œ"""
        try:
            prompt = f"""
            ë‹¤ìŒ ë¬¸ì„œ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ í•™ìˆ ì  ë³´ê³ ì„œ ì‘ì„±ì— í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
            
            ë¬¸ì„œ ë‚´ìš©:
            {content}
            
            ë¶„ì„ í•­ëª©:
            1. ì£¼ìš” ì£¼ì œ (ë©”ì¸ ì£¼ì œ 1ê°œ)
            2. í•µì‹¬ í‚¤ì›Œë“œ (5-10ê°œ)
            3. ì£¼ìš” ê°œë…ë“¤ (3-5ê°œ)
            4. ë¬¸ì„œì˜ ì „ì²´ì ì¸ ì„±ê²© (ì„¤ëª…ì , ë¶„ì„ì , ë¹„êµì  ë“±)
            5. í•™ë¬¸ ë¶„ì•¼ ë˜ëŠ” ë„ë©”ì¸
            
            JSON í˜•íƒœë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
            {{
                "main_topic": "ì£¼ìš” ì£¼ì œ",
                "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...],
                "key_concepts": ["ê°œë…1", "ê°œë…2", ...],
                "document_nature": "ë¬¸ì„œ ì„±ê²©",
                "academic_domain": "í•™ë¬¸ ë¶„ì•¼"
            }}
            """
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=1000
            )
            
            import json
            result = json.loads(response.choices[0].message.content)
            return result
            
        except Exception as e:
            logger.error(f"ë‚´ìš© ë¶„ì„ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "main_topic": "ì¢…í•© ë¶„ì„",
                "keywords": ["ë¶„ì„", "ì—°êµ¬", "ë‚´ìš©"],
                "key_concepts": ["ì£¼ìš” ê°œë…"],
                "document_nature": "ì¢…í•©ì ",
                "academic_domain": "ì¼ë°˜"
            }
    
    async def _generate_title_and_subtitle(self, analysis: Dict) -> Tuple[str, str]:
        """ì œëª©ê³¼ ë¶€ì œëª© ìƒì„±"""
        try:
            prompt = f"""
            ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìˆ ì  ë³´ê³ ì„œì˜ ì œëª©ê³¼ ë¶€ì œëª©ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
            
            ë¶„ì„ ê²°ê³¼:
            - ì£¼ìš” ì£¼ì œ: {analysis['main_topic']}
            - í‚¤ì›Œë“œ: {', '.join(analysis['keywords'])}
            - í•™ë¬¸ ë¶„ì•¼: {analysis['academic_domain']}
            
            ìš”êµ¬ì‚¬í•­:
            - ì œëª©: ê°„ê²°í•˜ê³  í•™ìˆ ì ì´ë©° ë‚´ìš©ì„ ì˜ í‘œí˜„í•˜ëŠ” ì œëª©
            - ë¶€ì œëª©: ì œëª©ì„ ë³´ì™„í•˜ê³  êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ì•”ì‹œí•˜ëŠ” ë¶€ì œëª©
            - í•œêµ­ì–´ë¡œ ì‘ì„±
            
            JSON í˜•íƒœë¡œ ë‹µë³€:
            {{
                "title": "ë³´ê³ ì„œ ì œëª©",
                "subtitle": "ë³´ê³ ì„œ ë¶€ì œëª©"
            }}
            """
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=500
            )
            
            import json
            result = json.loads(response.choices[0].message.content)
            return result["title"], result["subtitle"]
            
        except Exception as e:
            logger.error(f"ì œëª© ìƒì„± ì‹¤íŒ¨: {e}")
            return f"{analysis['main_topic']} ë¶„ì„ ë³´ê³ ì„œ", "ì¢…í•©ì  ì—°êµ¬ ë° ë¶„ì„"
    
    async def _generate_subtitle(self, title: str, analysis: Dict) -> str:
        """ì‚¬ìš©ì ì§€ì • ì œëª©ì— ëŒ€í•œ ë¶€ì œëª© ìƒì„±"""
        try:
            prompt = f"""
            ë‹¤ìŒ ì œëª©ì— ì–´ìš¸ë¦¬ëŠ” í•™ìˆ ì  ë¶€ì œëª©ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
            
            ì œëª©: {title}
            ì£¼ìš” ì£¼ì œ: {analysis['main_topic']}
            í‚¤ì›Œë“œ: {', '.join(analysis['keywords'])}
            
            ë¶€ì œëª© ìš”êµ¬ì‚¬í•­:
            - ì œëª©ì„ ë³´ì™„í•˜ê³  êµ¬ì²´í™”
            - í•™ìˆ ì  í‘œí˜„ ì‚¬ìš©
            - í•œêµ­ì–´ë¡œ ì‘ì„±
            - 20ì ë‚´ì™¸
            """
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=200
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"ë¶€ì œëª© ìƒì„± ì‹¤íŒ¨: {e}")
            return "ì¢…í•©ì  ì—°êµ¬ ë° ë¶„ì„"
    
    async def _generate_introduction(self, analysis: Dict, title: str) -> str:
        """ì„œë¡  ìƒì„±"""
        try:
            prompt = f"""
            ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìˆ ì  ë³´ê³ ì„œì˜ ì„œë¡ ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
            
            ë³´ê³ ì„œ ì œëª©: {title}
            ì£¼ìš” ì£¼ì œ: {analysis['main_topic']}
            í‚¤ì›Œë“œ: {', '.join(analysis['keywords'])}
            í•™ë¬¸ ë¶„ì•¼: {analysis['academic_domain']}
            
            ì„œë¡  ì‘ì„± ìš”êµ¬ì‚¬í•­:
            - ì—°êµ¬ì˜ ë°°ê²½ê³¼ ëª©ì  ì œì‹œ
            - ì£¼ìš” ì£¼ì œì˜ ì¤‘ìš”ì„± ì„¤ëª…
            - ë³´ê³ ì„œì˜ êµ¬ì„±ê³¼ ë²”ìœ„ ì•ˆë‚´
            - í•™ìˆ ì  í†¤ì•¤ë§¤ë„ˆ ìœ ì§€
            - 3-4 ë¬¸ë‹¨, 300-500ì ë‚´ì™¸
            - í•œêµ­ì–´ë¡œ ì‘ì„±
            """
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5,
                max_tokens=800
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"ì„œë¡  ìƒì„± ì‹¤íŒ¨: {e}")
            return f"ë³¸ ë³´ê³ ì„œëŠ” {analysis['main_topic']}ì— ê´€í•œ ì¢…í•©ì  ë¶„ì„ì„ ì œì‹œí•©ë‹ˆë‹¤."
    
    async def _generate_main_content(self, content: str, analysis: Dict) -> Dict:
        """ë³¸ë¡  ìƒì„± (ì—¬ëŸ¬ ì„¹ì…˜ìœ¼ë¡œ êµ¬ì„±)"""
        try:
            prompt = f"""
            ë‹¤ìŒ ë¬¸ì„œ ë‚´ìš©ê³¼ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìˆ ì  ë³´ê³ ì„œì˜ ë³¸ë¡ ì„ 3ê°œ ì„¹ì…˜ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”.
            
            ë¬¸ì„œ ë‚´ìš©:
            {content[:8000]}  # í† í° ì œí•œ ê³ ë ¤
            
            ë¶„ì„ ê²°ê³¼:
            - ì£¼ìš” ì£¼ì œ: {analysis['main_topic']}
            - í•µì‹¬ ê°œë…: {', '.join(analysis['key_concepts'])}
            - ë¬¸ì„œ ì„±ê²©: {analysis['document_nature']}
            
            ë³¸ë¡  êµ¬ì„± ìš”êµ¬ì‚¬í•­:
            - ì„¹ì…˜ 1: í˜„í™© ë° ë°°ê²½ ë¶„ì„
            - ì„¹ì…˜ 2: í•µì‹¬ ë‚´ìš© ë° ì£¼ìš” ë°œê²¬ì‚¬í•­
            - ì„¹ì…˜ 3: ì‹œì‚¬ì  ë° ì˜ë¯¸ í•´ì„
            - ê° ì„¹ì…˜ë³„ 500-800ì ë‚´ì™¸
            - ë…¼ë¦¬ì  íë¦„ê³¼ ì—°ê²°ì„± ìœ ì§€
            - êµ¬ì²´ì  ë‚´ìš©ê³¼ ì˜ˆì‹œ í¬í•¨
            - í•™ìˆ ì  í‘œí˜„ ì‚¬ìš©
            
            JSON í˜•íƒœë¡œ ë‹µë³€:
            {{
                "section_1": {{
                    "title": "ì„¹ì…˜1 ì œëª©",
                    "content": "ì„¹ì…˜1 ë‚´ìš©"
                }},
                "section_2": {{
                    "title": "ì„¹ì…˜2 ì œëª©", 
                    "content": "ì„¹ì…˜2 ë‚´ìš©"
                }},
                "section_3": {{
                    "title": "ì„¹ì…˜3 ì œëª©",
                    "content": "ì„¹ì…˜3 ë‚´ìš©"
                }}
            }}
            """
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5,
                max_tokens=2500
            )
            
            import json
            result = json.loads(response.choices[0].message.content)
            return result
            
        except Exception as e:
            logger.error(f"ë³¸ë¡  ìƒì„± ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ë³¸ë¡  êµ¬ì¡° ë°˜í™˜
            return {
                "section_1": {
                    "title": "í˜„í™© ë¶„ì„",
                    "content": f"{analysis['main_topic']}ì˜ í˜„ì¬ ìƒí™©ê³¼ ë°°ê²½ì„ ë¶„ì„í•©ë‹ˆë‹¤."
                },
                "section_2": {
                    "title": "ì£¼ìš” ë‚´ìš©",
                    "content": "í•µì‹¬ ë‚´ìš©ê³¼ ì£¼ìš” ë°œê²¬ì‚¬í•­ì„ ì •ë¦¬í•©ë‹ˆë‹¤."
                },
                "section_3": {
                    "title": "ì‹œì‚¬ì ",
                    "content": "ë¶„ì„ ê²°ê³¼ì˜ ì˜ë¯¸ì™€ ì‹œì‚¬ì ì„ ì œì‹œí•©ë‹ˆë‹¤."
                }
            }
    
    async def _generate_conclusion(self, analysis: Dict, title: str) -> str:
        """ê²°ë¡  ìƒì„±"""
        try:
            prompt = f"""
            ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìˆ ì  ë³´ê³ ì„œì˜ ê²°ë¡ ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
            
            ë³´ê³ ì„œ ì œëª©: {title}
            ì£¼ìš” ì£¼ì œ: {analysis['main_topic']}
            í•µì‹¬ ê°œë…: {', '.join(analysis['key_concepts'])}
            
            ê²°ë¡  ì‘ì„± ìš”êµ¬ì‚¬í•­:
            - ì£¼ìš” ë°œê²¬ì‚¬í•­ ìš”ì•½
            - í•µì‹¬ ë©”ì‹œì§€ ê°•ì¡°
            - í–¥í›„ ê³¼ì œë‚˜ ì œì–¸ í¬í•¨
            - ë³´ê³ ì„œì˜ ì˜ì˜ì™€ ê¸°ì—¬ë„ ì–¸ê¸‰
            - 3-4 ë¬¸ë‹¨, 300-500ì ë‚´ì™¸
            - í•™ìˆ ì  í†¤ì•¤ë§¤ë„ˆ ìœ ì§€
            - í•œêµ­ì–´ë¡œ ì‘ì„±
            """
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5,
                max_tokens=800
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"ê²°ë¡  ìƒì„± ì‹¤íŒ¨: {e}")
            return f"ë³¸ ë³´ê³ ì„œë¥¼ í†µí•´ {analysis['main_topic']}ì— ëŒ€í•œ ì¢…í•©ì  ì´í•´ë¥¼ ë„ëª¨í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤."
    
    async def _generate_metadata(
        self,
        selected_files: List[Dict],
        content: str,
        introduction: str,
        main_content: Dict,
        conclusion: str
    ) -> Dict:
        """ë³´ê³ ì„œ ë©”íƒ€ë°ì´í„° ìƒì„±"""
        try:
            # ì „ì²´ ë³´ê³ ì„œ ê¸¸ì´ ê³„ì‚°
            total_content = introduction + " ".join([
                section["content"] for section in main_content.values()
            ]) + conclusion
            
            word_count = len(total_content.replace(" ", ""))
            
            # ì˜ˆìƒ í˜ì´ì§€ ìˆ˜ ê³„ì‚° (í•œêµ­ì–´ ê¸°ì¤€ ì•½ 800ì/í˜ì´ì§€)
            estimated_pages = max(1, word_count // 800)
            
            return {
                "total_files": len(selected_files),
                "selected_files_count": len(selected_files),
                "total_pages": estimated_pages,
                "word_count": word_count,
                "character_count": len(total_content),
                "generation_model": self.model,
                "sections_count": len(main_content) + 2  # ì„œë¡  + ë³¸ë¡ ì„¹ì…˜ë“¤ + ê²°ë¡ 
            }
            
        except Exception as e:
            logger.error(f"ë©”íƒ€ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "total_files": len(selected_files),
                "selected_files_count": len(selected_files),
                "total_pages": 1,
                "word_count": 1000,
                "character_count": 1000,
                "generation_model": self.model,
                "sections_count": 5
            }
    
    async def format_report_text(self, report_data: Dict) -> str:
        """ë³´ê³ ì„œë¥¼ ì½ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ í¬ë§·íŒ…"""
        try:
            formatted_text = f"""
# {report_data['title']}
## {report_data['subtitle']}

---

### ğŸ“‹ ë³´ê³ ì„œ ì •ë³´
- **ìƒì„±ì¼**: {report_data['created_at'].strftime('%Yë…„ %mì›” %dì¼')}
- **ëŒ€ìƒ íŒŒì¼ ìˆ˜**: {report_data['metadata']['selected_files_count']}ê°œ
- **ì˜ˆìƒ í˜ì´ì§€**: {report_data['metadata']['total_pages']}í˜ì´ì§€
- **ì´ ë¬¸ì ìˆ˜**: {report_data['metadata']['character_count']:,}ì

---

## 1. ì„œë¡ 

{report_data['report_structure']['introduction']}

---

## 2. ë³¸ë¡ 

### 2.1 {report_data['report_structure']['main_content']['section_1']['title']}

{report_data['report_structure']['main_content']['section_1']['content']}

### 2.2 {report_data['report_structure']['main_content']['section_2']['title']}

{report_data['report_structure']['main_content']['section_2']['content']}

### 2.3 {report_data['report_structure']['main_content']['section_3']['title']}

{report_data['report_structure']['main_content']['section_3']['content']}

---

## 3. ê²°ë¡ 

{report_data['report_structure']['conclusion']}

---

### ğŸ“Š ë¶„ì„ ìš”ì•½
- **ì£¼ìš” ì£¼ì œ**: {report_data['analysis_summary']['main_topic']}
- **í•µì‹¬ í‚¤ì›Œë“œ**: {', '.join(report_data['analysis_summary']['keywords'])}
- **í•™ë¬¸ ë¶„ì•¼**: {report_data['analysis_summary']['academic_domain']}

### ğŸ“ ì°¸ì¡° íŒŒì¼ ëª©ë¡
"""
            
            for i, file_info in enumerate(report_data['selected_files'], 1):
                formatted_text += f"{i}. {file_info['filename']} ({file_info['file_type'].upper()})\n"
            
            return formatted_text
            
        except Exception as e:
            logger.error(f"ë³´ê³ ì„œ í…ìŠ¤íŠ¸ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            return "ë³´ê³ ì„œ í¬ë§·íŒ… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤." 